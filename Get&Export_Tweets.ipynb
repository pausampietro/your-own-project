{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install (if needed) and Import Libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tweepy\n",
    "import requests as re\n",
    "import json\n",
    "import sys\n",
    "import pymysql\n",
    "from sqlalchemy import create_engine\n",
    "import pandas as pd\n",
    "import operator\n",
    "#!{sys.executable} -m pip install tweepy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conection to Google Cloud Database (to export news dataframes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = 'mysql+pymysql'\n",
    "ip = ''\n",
    "username = ''\n",
    "password = ''\n",
    "db = ''\n",
    "\n",
    "cs  = f'{driver}://{username}:{password}@{ip}/{db}'\n",
    "engine = create_engine(cs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Authentication for twitter API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "consumer_token = ''\n",
    "consumer_secret = ''\n",
    "access_token = ''\n",
    "access_secret = ''\n",
    "\n",
    "auth = tweepy.OAuthHandler(consumer_token, consumer_secret)\n",
    "auth.set_access_token(access_token, access_secret)\n",
    "api = tweepy.API(auth)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting tweets from diferent sources (timelines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# twitter users used\n",
    "list_pages = ['LaVanguardia', 'elperiodico', 'diariARA', 'elmundoes', 'el_pais', 'elnacionalcat']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LaVanguardia  start\n",
      "LaVanguardia  ends\n",
      "elperiodico  start\n",
      "elperiodico  ends\n",
      "diariARA  start\n",
      "diariARA  ends\n",
      "elmundoes  start\n",
      "elmundoes  ends\n",
      "el_pais  start\n",
      "el_pais  ends\n",
      "elnacionalcat  start\n",
      "elnacionalcat  ends\n"
     ]
    }
   ],
   "source": [
    "# loop in order to get tweets from different user's timelines\n",
    "\n",
    "for page in list_pages:\n",
    "    tweets = api.user_timeline(screen_name=page)\n",
    "    \n",
    "    print(page, ' start')\n",
    "    # generate series with the content of the tweets\n",
    "    date = pd.Series([tweet._json['created_at'] for tweet in tweets])\n",
    "    text = pd.Series([tweet._json['text'] for tweet in tweets])\n",
    "    retweets = pd.Series([tweet._json['retweet_count'] for tweet in tweets])\n",
    "    likes = pd.Series([tweet._json['favorite_count'] for tweet in tweets])\n",
    "    media = pd.Series([page for tweet in tweets])\n",
    "    \n",
    "    list_urls = []\n",
    "    for tweet in tweets:\n",
    "        elem = ''\n",
    "        if tweet._json['entities']['urls'] != []:\n",
    "            elem = tweet._json['entities']['urls'][0]['expanded_url']\n",
    "            if tweet._json['entities']['urls'][0]['expanded_url'].find('https://') > -1:\n",
    "                elem = elem.split('https://')[1]\n",
    "            if tweet._json['entities']['urls'][0]['expanded_url'].find('?') > -1:\n",
    "                elem = elem.split('?')[0]\n",
    "        list_urls.append(elem) \n",
    "            \n",
    "    url = pd.Series(list_urls)\n",
    "\n",
    "\n",
    "    # create one dataframe with all the tweets from each source\n",
    "    data = pd.DataFrame({'text': text, 'url': url, 'date': date, 'retweets': retweets, 'likes': likes, 'media': media})\n",
    "    \n",
    "    print(page, ' ends')\n",
    "    \n",
    "    # export dataframe to database with all the tweets\n",
    "    data.to_sql(con=engine, name='tweets', if_exists='append')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Update Dicttionary with words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ssql = '''SELECT \n",
    "    MAX(tweets.`index`) AS `index`,\n",
    "    MAX(`text`) AS `text`,\n",
    "    MAX(url) AS url,\n",
    "    MAX(`date`) AS `date`,\n",
    "    MAX(retweets) AS retweets,\n",
    "    MAX(likes) AS likes,\n",
    "    MAX(tweets.media) AS media\n",
    "FROM\n",
    "    tweets\n",
    "GROUP BY tweets.`text`'''\n",
    "\n",
    "auxdf = pd.read_sql(Ssql,engine)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### +Function that counts how many likes and interactions get EACH WORD (number of likes+retweets of the tweets where the word appears)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def export_words_values(field, likes, retweets):\n",
    "    for word in field.split(' '):\n",
    "        clean_word = word.strip('Â¿,.\":;/?!\\n ')\n",
    "        if 'http' not in word:\n",
    "            if clean_word in words.keys():\n",
    "                words[clean_word][0] += likes+retweets\n",
    "                words[clean_word][1] += 1\n",
    "            else:\n",
    "                words[clean_word] = [likes+retweets, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### +Initialize an empty dictionary and goes through the dataframe exporting words & interactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = auxdf[['text','likes', 'retweets']].apply(lambda x: export_words_values(x['text'], x['likes'], x['retweets']), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a sorted dataframe with all the words in tweets and the amount of interactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = sorted(words.items(), key=operator.itemgetter(1), reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>interactions</th>\n",
       "      <th>appearances</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>de</td>\n",
       "      <td>23604</td>\n",
       "      <td>1226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>la</td>\n",
       "      <td>13123</td>\n",
       "      <td>685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>en</td>\n",
       "      <td>8849</td>\n",
       "      <td>461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>a</td>\n",
       "      <td>7477</td>\n",
       "      <td>479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>el</td>\n",
       "      <td>6648</td>\n",
       "      <td>455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>y</td>\n",
       "      <td>6503</td>\n",
       "      <td>231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>que</td>\n",
       "      <td>6384</td>\n",
       "      <td>424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>con</td>\n",
       "      <td>5950</td>\n",
       "      <td>120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>un</td>\n",
       "      <td>5138</td>\n",
       "      <td>228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>del</td>\n",
       "      <td>3804</td>\n",
       "      <td>268</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  word  interactions  appearances\n",
       "0   de         23604         1226\n",
       "1   la         13123          685\n",
       "2   en          8849          461\n",
       "3    a          7477          479\n",
       "4   el          6648          455\n",
       "5    y          6503          231\n",
       "6  que          6384          424\n",
       "7  con          5950          120\n",
       "8   un          5138          228\n",
       "9  del          3804          268"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table_words = pd.DataFrame({'word': [x[0] for x in words], 'interactions': [x[1][0] for x in words], 'appearances': [x[1][1] for x in words]}) \n",
    "table_words.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export the table to database (replace if exist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "table_words.to_sql(con=engine, name='words', if_exists='replace')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
